{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cách load dữ liệu truyền thống**\n",
    "<img src=\"./images/traditional_load_data.png\">\n",
    "\n",
    "**Cách load dữ liệu bằng cách Pipeline**\n",
    "<img src=\"./images/pipeline_load_data.png\">\n",
    "Trong quá trình làm việc với TensorFlow, cách dễ dàng nhất để cấu hình một input pipeline hiệu quả là sử dụng định dạng TFRecord, một định dạng dữ liệu kiểu nhị phân được hỗ trợ bởi TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol Buffers & TFRecord\n",
    "**Protocol Buffers** định nghĩa cách serialize những dữ liệu có cấu trúc thành dữ liệu nhị phân. <br>\n",
    "Cấu trúc dữ liệu được viết dưới dạng protocol bufer message và lưu thành tệp .proto. Có thể coi protocol buffer là 1 optimize version của XML nhưng là cho việc xây dựng cấu trúc dữ liệu. Ví dụ:\n",
    "\n",
    "**TFRecord** là một định dạng đơn giản để lưu trữ một chuỗi các bản ghi nhị phân. 1 tệp TFRecord chứa một chuỗi các records của observation. Các tập chỉ có thể được đọc tuần tự.<br>\n",
    "\n",
    "TensorFlow sử dụng Protocol Buffers để định nghĩa cấu trúc của dữ liệu dạng TFRecord. <br>\n",
    "Một trường dữ liệu (Ví dụ: ảnh đầu vào và nhãn của ảnh đó) được gọi là một Example<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 tf.Example là 1 ánh xạ {\"string\": tf.train.Feature}.** <br>\n",
    "**Data types for tf.Example**\n",
    "\n",
    "<img src=\"./images/Tf_Feature_datatype.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert a standard TensorFlow type to a tf.Example-compatible tf.train.Feature, you can use the shortcut functions below. Note that each function takes a scalar input value and returns a tf.train.Feature containing one of the three list types above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes_list {\n",
      "  value: \"test_string\"\n",
      "}\n",
      "\n",
      "bytes_list {\n",
      "  value: \"test_bytes\"\n",
      "}\n",
      "\n",
      "float_list {\n",
      "  value: 2.7182817459106445\n",
      "}\n",
      "\n",
      "int64_list {\n",
      "  value: 1\n",
      "}\n",
      "\n",
      "int64_list {\n",
      "  value: 1\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_bytes_feature(b'test_string'))\n",
    "print(_bytes_feature(u'test_bytes'.encode('utf-8')))\n",
    "\n",
    "print(_float_feature(np.exp(1)))\n",
    "\n",
    "print(_int64_feature(True))\n",
    "print(_int64_feature(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x12\\x06\\n\\x04T\\xf8-@'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = _float_feature(np.exp(1))\n",
    "feature.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "In this notebook, you will create a dataset using NumPy.\n",
    "\n",
    "This dataset will have 4 features:\n",
    "- a boolean feature, False or True with equal probability\n",
    "- an integer feature uniformly randomly chosen from [0, 5]\n",
    "- a string feature generated from a string table by using the integer feature as an index\n",
    "- a float feature from a standard normal distribution\n",
    "\n",
    "Consider a sample consisting of 10,000 independently and identically distributed observations from each of the above distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of observations in the dataset.\n",
    "n_observations = int(1e4)\n",
    "\n",
    "# Boolean feature, encoded as False or True.\n",
    "feature0 = np.random.choice([False, True], n_observations)\n",
    "\n",
    "# Integer feature, random from 0 to 4.\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "\n",
    "# String feature\n",
    "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
    "feature2 = strings[feature1]\n",
    "\n",
    "# Float feature, from a standard normal distribution\n",
    "feature3 = np.random.randn(n_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tổng quát quá trình tạo 1 tf.Example message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Within each observation, each value needs to be converted to a tf.train.Feature containing one of the 3 compatible types, using one of the functions above.\n",
    "2. You create a map (dictionary) from the feature name string to the encoded feature value produced in #1.\n",
    "3. The map produced in step 2 is converted to a Features message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\nR\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04[\\xd3|?\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04'\n"
     ]
    }
   ],
   "source": [
    "# Serialize a sample from observation to a Example\n",
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "    feature = {\n",
    "      'feature0': _int64_feature(feature0),\n",
    "      'feature1': _int64_feature(feature1),\n",
    "      'feature2': _bytes_feature(feature2),\n",
    "      'feature3': _float_feature(feature3),\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "example = serialize_example(False, 4, b'goat', 0.9876)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord files using tf.data\n",
    "### **Writing a TFRecord file**<br>\n",
    "Cách đơn giản nhất để tạo dataset từ các features là sử dụng method **from_tensor_slices**<br>\n",
    "Từ đó có thể can thiệp để tiền xử lý thông qua method **tf.data.Dataset.map**, áp dụng cho mỗi element trong Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/duyvc/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "b'\\nU\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x17\\n\\x08feature2\\x12\\x0b\\n\\t\\n\\x07chicken\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xa6y\\xbc?'\n"
     ]
    }
   ],
   "source": [
    "for feature0, feature1, feature2, feature3 in dataset.take(1):\n",
    "    serialized_example = serialize_example(feature0, \n",
    "                                           feature1, \n",
    "                                           feature2, \n",
    "                                           feature3)\n",
    "    print(serialized_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to write the data into a TFRecords file we need to convert each data point into a byte-string following the above process and write it into file using a tf.io.TFRecordsWriter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data.tfrecords'\n",
    "with tf.io.TFRecordWriter(file_path) as writer:\n",
    "    for feature0, feature1, feature2, feature3 in dataset:\n",
    "        serialized_example = serialize_example(feature0, \n",
    "                                     feature1, \n",
    "                                     feature2, \n",
    "                                     feature3)    \n",
    "        writer.write(serialized_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read a TFRecord file**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV1 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = [file_path] # We have only one file\n",
    "raw_dataset = tf.data.TFRecordDataset(file_paths)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: id=90071, shape=(), dtype=string, numpy=b'\\nU\\n\\x17\\n\\x08feature2\\x12\\x0b\\n\\t\\n\\x07chicken\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xa6y\\xbc?\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x02'>\n",
      "<tf.Tensor: id=90073, shape=(), dtype=string, numpy=b'\\nS\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xb33\\x97\\xbf'>\n",
      "<tf.Tensor: id=90075, shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03dog\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xad\\xc9\\x91\\xbf'>\n",
      "<tf.Tensor: id=90077, shape=(), dtype=string, numpy=b'\\nR\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\x03\\xecL\\xbd'>\n",
      "<tf.Tensor: id=90079, shape=(), dtype=string, numpy=b'\\nR\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x045\\xbf\\xf0\\xbf'>\n",
      "<tf.Tensor: id=90081, shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03dog\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04;\\xb8\\xe1<'>\n",
      "<tf.Tensor: id=90083, shape=(), dtype=string, numpy=b'\\nR\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xf3\\xd5\\x91>\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04'>\n",
      "<tf.Tensor: id=90085, shape=(), dtype=string, numpy=b'\\nS\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\x06\\x8b\\x12\\xbf'>\n",
      "<tf.Tensor: id=90087, shape=(), dtype=string, numpy=b'\\nS\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xc8\\x14\\xff?\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse'>\n",
      "<tf.Tensor: id=90089, shape=(), dtype=string, numpy=b'\\nU\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04/\\x95\\x10\\xc0\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x17\\n\\x08feature2\\x12\\x0b\\n\\t\\n\\x07chicken'>\n"
     ]
    }
   ],
   "source": [
    "for raw_record in raw_dataset.take(10):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # Parse the input `tf.Example` proto using the dictionary above.\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {feature0: (), feature1: (), feature2: (), feature3: ()}, types: {feature0: tf.int64, feature1: tf.int64, feature2: tf.string, feature3: tf.float32}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature0': <tf.Tensor: id=90119, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=90120, shape=(), dtype=int64, numpy=2>, 'feature2': <tf.Tensor: id=90121, shape=(), dtype=string, numpy=b'chicken'>, 'feature3': <tf.Tensor: id=90122, shape=(), dtype=float32, numpy=1.4724624>}\n",
      "{'feature0': <tf.Tensor: id=90127, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=90128, shape=(), dtype=int64, numpy=3>, 'feature2': <tf.Tensor: id=90129, shape=(), dtype=string, numpy=b'horse'>, 'feature3': <tf.Tensor: id=90130, shape=(), dtype=float32, numpy=-1.1812652>}\n",
      "{'feature0': <tf.Tensor: id=90135, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=90136, shape=(), dtype=int64, numpy=1>, 'feature2': <tf.Tensor: id=90137, shape=(), dtype=string, numpy=b'dog'>, 'feature3': <tf.Tensor: id=90138, shape=(), dtype=float32, numpy=-1.1389672>}\n",
      "{'feature0': <tf.Tensor: id=90143, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=90144, shape=(), dtype=int64, numpy=4>, 'feature2': <tf.Tensor: id=90145, shape=(), dtype=string, numpy=b'goat'>, 'feature3': <tf.Tensor: id=90146, shape=(), dtype=float32, numpy=-0.050029766>}\n",
      "{'feature0': <tf.Tensor: id=90151, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=90152, shape=(), dtype=int64, numpy=4>, 'feature2': <tf.Tensor: id=90153, shape=(), dtype=string, numpy=b'goat'>, 'feature3': <tf.Tensor: id=90154, shape=(), dtype=float32, numpy=-1.8808352>}\n",
      "{'feature0': <tf.Tensor: id=90159, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=90160, shape=(), dtype=int64, numpy=1>, 'feature2': <tf.Tensor: id=90161, shape=(), dtype=string, numpy=b'dog'>, 'feature3': <tf.Tensor: id=90162, shape=(), dtype=float32, numpy=0.027553668>}\n",
      "{'feature0': <tf.Tensor: id=90167, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=90168, shape=(), dtype=int64, numpy=4>, 'feature2': <tf.Tensor: id=90169, shape=(), dtype=string, numpy=b'goat'>, 'feature3': <tf.Tensor: id=90170, shape=(), dtype=float32, numpy=0.28483543>}\n",
      "{'feature0': <tf.Tensor: id=90175, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=90176, shape=(), dtype=int64, numpy=3>, 'feature2': <tf.Tensor: id=90177, shape=(), dtype=string, numpy=b'horse'>, 'feature3': <tf.Tensor: id=90178, shape=(), dtype=float32, numpy=-0.5724338>}\n",
      "{'feature0': <tf.Tensor: id=90183, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=90184, shape=(), dtype=int64, numpy=3>, 'feature2': <tf.Tensor: id=90185, shape=(), dtype=string, numpy=b'horse'>, 'feature3': <tf.Tensor: id=90186, shape=(), dtype=float32, numpy=1.9928217>}\n",
      "{'feature0': <tf.Tensor: id=90191, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=90192, shape=(), dtype=int64, numpy=2>, 'feature2': <tf.Tensor: id=90193, shape=(), dtype=string, numpy=b'chicken'>, 'feature3': <tf.Tensor: id=90194, shape=(), dtype=float32, numpy=-2.2591054>}\n"
     ]
    }
   ],
   "source": [
    "for parsed_record in parsed_dataset.take(10):\n",
    "    print(repr(parsed_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
