{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bias/Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias là gì? \n",
    "Bias là sự sai khác giữa trung bình dự đoán của mô hình chúng ta xây dựng với giá trị chính xác đang cố gắng để dự đoán. Một mô hình với trị số bias cao đồng nghĩa với việc mô hình đó không quan tâm nhiều tới dữ liệu huấn luyện, khiến cho mô hình trở nên đơn giản quá. Nó thường dẫn đến việc mô hình có mức độ lỗi cao cả trên tập huấn luyện và tập kiểm thử.\n",
    "\n",
    "**Lưu ý** không nhầm lẫn với bias parameter trong các mô hình ML thông thường.\n",
    "\n",
    "### Variance là gì? \n",
    "Variance đặc trưng cho mức độ tản mát của giá trị dự đoán cho điểm dữ liệu. Mô hình với mức độ variance cao tập trung chú ý nhiều vào dữ liệu huấn luyện và không mang được tính tổng quát trên dữ liệu chưa gặp bao giờ. Từ đó dẫn đến mô hình đạt được kết quả cực kì tốt trên tập dữ liệu huấn luyện, tuy nhiên kết quả rất tệ với tập dữ liệu kiểm thử"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/bias_variance.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前回\n",
    "- MNISTのデータセット\n",
    "- 28×28のモノクロ画像\n",
    "- 多層パーセプトロン（MLP）\n",
    "- 入力数：784個\n",
    "- パラメータ数：785(バイアス含む)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/MLPModel_summary.png\" style=\"margin-left: -10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 今回\n",
    "- CIFAR-10のデータセット\n",
    "- 32×32のカラー画像\n",
    "- 畳み込みニューラルネットワーク（CNN）\n",
    "- 入力数：120000個\n",
    "パラメータが多くなるほど最適化が難しくなる\n",
    "=> **畳み込みニューラルネットワーク（CNN）の導入**\n",
    "\n",
    "Số lượng tham số càng lớn, việc tối ưu hóa càng khó khăn (ở đây 32* 32* 3 so với 28* 28 và có thể ảnh còn có kích thước lớn hơn nữa...). Khi đó nảy ra ý tưởng sử dụng mạng tích chập CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "- CNNとは、入力データである画像の性質を利用して、パラメータの数を削減している。(*)\n",
    "- CNNの一番の特徴は、畳み込み層とプーリング層の繰り返し。\n",
    "\n",
    "Ý tưởng chính là từ ảnh đầu vào có thể trích suất các đặc trưng quan trọng (thay vì toàn bộ ảnh như lần trc). Nhờ đó mà giảm được số lượng tham số mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込み層とプーリング層\n",
    "- CNNの一番の特徴は、畳み込み層とプーリング層の繰り返し。Cấu trúc của CNN là sự lặp lại của lớp tích chập và lớp gộp.\n",
    "\n",
    "\n",
    "- 畳み込み層とは、画像に対してカーネル（フィルタ）(kernel or filter)を適用していき、画像の特徴量を抽出するような役目を担う層。Lớp tích chập(Conv) là một lớp đóng vai trò áp dụng kernel (bộ lọc) cho hình ảnh và trích xuất các đặc trưng của hình ảnh.\n",
    "\n",
    "\n",
    "- 最適化が必要な重みパラメータの数は画像のサイズではなくフィルタのサイズに依存するため、MLPと違い、画像のサイズが大きくなっても、パラメータ数が増大しない。Số lượng tham số cần được tối ưu hóa phụ thuộc vào số lượng các kernel trong bộ lọc, không phải kích thước của hình ảnh, vì vậy không giống như MLP, số lượng tham số không tăng ngay cả khi kích thước của hình ảnh tăng.\n",
    "\n",
    "\n",
    "- プーリング層とは、画像を縮小するような層のことで、小さな位置変化に対して頑健にするような役目を担っている。Lớp gộp (Pooling) có vai trò giảm kích thước hình ảnh, đồng thời giảm nhiễu ở các điểm ảnh (lấy average/max của 1 vùng pixel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込み層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/conv_sample.png\" style=\"height: 300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ trên mô tả việc thực hiện tích chập với kernel 2 chiều. Phép tích chập gồm các tham số cơ bản: kernel size (3* 3 hay 5* 5 ...), stride, padding \n",
    "\n",
    "Đối với các bài toán đầu vào ảnh màu (3 channel), kernel 3 chiều được áp dụng như sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/conv_kernel3D.png\" style=\"height: 350px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/conv_kernel3D(2).png\" style=\"height: 200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MLPでは入力データのサイズが大きくなるほど、パラメータ数が増大していきます。\n",
    "- 畳み込み層では、入力データのサイズが大きくなっても、特徴マップのサイズは増えますが、カーネルのサイズ、\n",
    "つまり重みパラメータ数は変化しません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プーリング層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プーリング層にもいくつか種類がありますが、最もよく使われるマックスプーリングでは、入力データを小さな領域に分割し、各領域の最大値を取ってくることでデータを縮小します。データが縮小されるため、計算コストを下げることに加え、各領域内の位置の違いを無視するため、小さな位置変化に対してモデルを構築することが出来る。\n",
    "\n",
    "Có 1 số kiểu pooling (phổ biến nhất trong đó là max-pooling マックスプーリング)\n",
    "\n",
    "Việc thêm pooling layer vào mô hình vừa có tác dụng giảm số lượng tham số mô hình, vừa tránh sự khác biệt nhỏ phải học khi có 1 pixel sai khác trong vùng pooling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/pooling.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
