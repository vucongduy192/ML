{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZJ3uY9O17VN"
   },
   "source": [
    "# Save and load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBdde4YJeJKF"
   },
   "source": [
    "Model có thể được save trong khi hoặc sau khi training. \n",
    "\n",
    "Điều này có lợi cho việc tránh phải training trong thời gian dài và chia sẻ mô hình đã training cho người khác. \n",
    "\n",
    "### Options\n",
    "\n",
    "Có nhiều cách khác nhau để lưu các mô hình TensorFlow, tùy thuộc vào API bạn đang sử dụng. Hướng dẫn này sử dụng tf.keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xCUREq7WXgvg"
   },
   "source": [
    "## Setup\n",
    "\n",
    "### Installs and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7l0MiTOrXtNv"
   },
   "source": [
    "Install and import TensorFlow and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzIOVSdnMYyO"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "!pip install -q pyyaml h5py  # Required to save models in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Nm7Tyb-gRt-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbGsznErXWt6"
   },
   "source": [
    "### Get an example dataset\n",
    "\n",
    "To demonstrate how to save and load weights, you'll use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). To speed up these runs, use the first 1000 examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rGfFwE9XVwz"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "anG3iVoXyZGI"
   },
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wynsOBfby0Pa"
   },
   "source": [
    "Start by building a simple sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HZbJIjxyX1S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "soDE0W_KH8rG"
   },
   "source": [
    "## Save checkpoints during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mRyd5qQQIXZm"
   },
   "source": [
    "Bạn có thể sử dụng mô hình đã được đào tạo mà không cần phải đào tạo lại hoặc trong trường hợp quá trình đào tạo xảy ra gián đoạn, mô hình sẽ tiếp tục được đào tạo tại điểm gián đoạn đó. The `tf.keras.callbacks.ModelCheckpoint` callback cho phép lưu mô hình trong cả khi **during training** hoặc **the end of training**.\n",
    "\n",
    "### Checkpoint callback usage\n",
    "\n",
    "Create a `tf.keras.callbacks.ModelCheckpoint` callback thế lưu mô hình khi **during training**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFPuhwntH8VH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      " 928/1000 [==========================>...] - ETA: 0s - loss: 1.2334 - accuracy: 0.6379\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 1.1896 - accuracy: 0.6530 - val_loss: 0.7383 - val_accuracy: 0.7740\n",
      "Epoch 2/10\n",
      " 896/1000 [=========================>....] - ETA: 0s - loss: 0.4359 - accuracy: 0.8683\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 362us/sample - loss: 0.4423 - accuracy: 0.8630 - val_loss: 0.5677 - val_accuracy: 0.8220\n",
      "Epoch 3/10\n",
      " 928/1000 [==========================>...] - ETA: 0s - loss: 0.2886 - accuracy: 0.9159\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 311us/sample - loss: 0.2983 - accuracy: 0.9160 - val_loss: 0.4609 - val_accuracy: 0.8480\n",
      "Epoch 4/10\n",
      " 896/1000 [=========================>....] - ETA: 0s - loss: 0.2065 - accuracy: 0.9442\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 313us/sample - loss: 0.2048 - accuracy: 0.9460 - val_loss: 0.4314 - val_accuracy: 0.8640\n",
      "Epoch 5/10\n",
      " 928/1000 [==========================>...] - ETA: 0s - loss: 0.1454 - accuracy: 0.9731\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 345us/sample - loss: 0.1487 - accuracy: 0.9700 - val_loss: 0.4453 - val_accuracy: 0.8610\n",
      "Epoch 6/10\n",
      " 768/1000 [======================>.......] - ETA: 0s - loss: 0.0991 - accuracy: 0.9818\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 343us/sample - loss: 0.1128 - accuracy: 0.9780 - val_loss: 0.3920 - val_accuracy: 0.8660\n",
      "Epoch 7/10\n",
      " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0880 - accuracy: 0.9877\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 314us/sample - loss: 0.0861 - accuracy: 0.9890 - val_loss: 0.4085 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.0642 - accuracy: 0.9929\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 395us/sample - loss: 0.0638 - accuracy: 0.9930 - val_loss: 0.3896 - val_accuracy: 0.8780\n",
      "Epoch 9/10\n",
      " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0440 - accuracy: 1.0000\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 315us/sample - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      " 864/1000 [========================>.....] - ETA: 0s - loss: 0.0366 - accuracy: 0.9988\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 323us/sample - loss: 0.0372 - accuracy: 0.9990 - val_loss: 0.3981 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4749e5dc50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Tạo callback để lưu trọng số của model\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model sử dụng callback vừa tạo\n",
    "model.fit(train_images, \n",
    "          train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])  # Truyền trường callback để training\n",
    "\n",
    "# This may generate warnings related to saving the state of the optimizer.\n",
    "# These warnings (and similar warnings throughout this notebook)\n",
    "# are in place to discourage outdated usage, and can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXG5FVKFOVQ3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  cp.ckpt.data-00000-of-00001  cp.ckpt.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlRN_f56Pqa9"
   },
   "source": [
    "Tạo một mô hình mới chưa được đào tạo. Khi khôi phục một mô hình chỉ từ trọng số, bạn phải có một mô hình có cùng kiến trúc với mô hình ban đầu. Nếu mô hình có cùng kiến trúc, bạn có thể chia sẻ trọng số có chu đó là một hình thức model khác. \n",
    "\n",
    "Bây giờ xây dựng lại một mô hình mới chưa được đào tạo và đánh giá nó trên bộ thử nghiệm. Một mô hình chưa được đào tạo sẽ có độ chính xác ~ 10%:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fp5gbuiaPqCT",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1 - 0s - loss: 2.2127 - accuracy: 0.1130\n",
      "Untrained model, accuracy: 11.30%\n"
     ]
    }
   ],
   "source": [
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DTKpZssRSo3"
   },
   "source": [
    "Then load the weights from the checkpoint and re-evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2IZxbwiRRSD2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1 - 0s - loss: 0.4397 - accuracy: 0.8700\n",
      "Restored model, accuracy: 87.00%\n"
     ]
    }
   ],
   "source": [
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bpAbKkAyVPV8"
   },
   "source": [
    "### Checkpoint callback options\n",
    "Callback cung cấp những lựa chọn cho việc cung cấp tên cụ thể cho mỗi checkpoints và điều chỉnh tần số của checkpointing.\n",
    "Đào tạo một model mới, và lưu tên duy nhất cho mỗi checkpoint cho mỗi 5 epochs 1 lần :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQF_dlgIVOvq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
      "\n",
      "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
      "\n",
      "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
      "\n",
      "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
      "\n",
      "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f475dedd470>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thêm thành phần epoch trong file name (uses `str.format`)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Tạo callback và lưu lại trọng số của model đối với mỗi 5 epoch\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    period=5)\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "              train_labels,\n",
    "              epochs=50, \n",
    "              callbacks=[cp_callback],\n",
    "              validation_data=(test_images,test_labels),\n",
    "              verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1zFrKTjjavWI"
   },
   "source": [
    "Now, look at the resulting checkpoints and choose the latest one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p64q3-V4sXt0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t\t  cp-0025.ckpt.index\r\n",
      "cp-0000.ckpt.data-00000-of-00001  cp-0030.ckpt.data-00000-of-00001\r\n",
      "cp-0000.ckpt.index\t\t  cp-0030.ckpt.index\r\n",
      "cp-0005.ckpt.data-00000-of-00001  cp-0035.ckpt.data-00000-of-00001\r\n",
      "cp-0005.ckpt.index\t\t  cp-0035.ckpt.index\r\n",
      "cp-0010.ckpt.data-00000-of-00001  cp-0040.ckpt.data-00000-of-00001\r\n",
      "cp-0010.ckpt.index\t\t  cp-0040.ckpt.index\r\n",
      "cp-0015.ckpt.data-00000-of-00001  cp-0045.ckpt.data-00000-of-00001\r\n",
      "cp-0015.ckpt.index\t\t  cp-0045.ckpt.index\r\n",
      "cp-0020.ckpt.data-00000-of-00001  cp-0050.ckpt.data-00000-of-00001\r\n",
      "cp-0020.ckpt.index\t\t  cp-0050.ckpt.index\r\n",
      "cp-0025.ckpt.data-00000-of-00001\r\n"
     ]
    }
   ],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AN_fnuyR41H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2/cp-0050.ckpt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zk2ciGbKg561"
   },
   "source": [
    "Note: mặc định của tensorflow chỉ lưu 5 checkpoint gần nhất.\n",
    "\n",
    "To test, reset the model and load the latest checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3M04jyK-H3QK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1 - 0s - loss: 0.5902 - accuracy: 0.8750\n",
      "Restored model, accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Load the previously saved weights\n",
    "model.load_weights(latest)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2OxsJOTHxia"
   },
   "source": [
    "## What are these files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JtdYhvWnH2ib"
   },
   "source": [
    "Filé chứa các trọng số được đào tạo ở định dạng nhị phân. Checkpoints chứa:\n",
    "* Một hoặc nhiều phân đoạn có chứa trọng số của mô hình.\n",
    "* Một index file cho biết trọng số nào được lưu trong phân đoạn nào.\n",
    "\n",
    "Nếu bạn chỉ đào tạo một mô hình trên một máy duy nhất,bạn sẽ có một phân đoạn với hậu tố: `.data-00000-of-00001`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_FA-ZvxuXQV"
   },
   "source": [
    "## Manually save weights\n",
    "Cách save model đơn giản với phương thức `Model.save_weights`. \n",
    "Mặc định, tf.keras và save_weights nói riêng sử dụng định dạng Checkpoint với đuôi .ckpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7W5plyZ-u9X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "1000/1 - 0s - loss: 0.5902 - accuracy: 0.8750\n",
      "Restored model, accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Evaluate the model\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kOGlxPRBEvV1"
   },
   "source": [
    "## Lưu toàn bộ model\n",
    "\n",
    "Gọi model.save để lưu cấu trúc, trọng số và cấu hình đào tạo của model trong một file/folder. Điều này cho phép bạn xuất một model để nó có thể được sử dụng mà không cần sử dụng code Python. Bạn có thể tiếp tục đào tạo từ chính xác nơi bạn rời khỏi trong quá trình training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkGwf-50zLNn"
   },
   "source": [
    "### HDF5 format\n",
    "\n",
    "Keras cung cấp định dạng cơ bản bằng cách sử dụng tiêu chuẩn HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2dkmJVCGUia"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 1.1438 - accuracy: 0.6790\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 171us/sample - loss: 0.4207 - accuracy: 0.8850\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 175us/sample - loss: 0.2808 - accuracy: 0.9260\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 185us/sample - loss: 0.2083 - accuracy: 0.9480\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 192us/sample - loss: 0.1629 - accuracy: 0.9660\n"
     ]
    }
   ],
   "source": [
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWmttMOqS68S"
   },
   "source": [
    "Now, recreate the model from that file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NDMO_7kS6Do"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JXQpbTicTBwt"
   },
   "source": [
    "Check its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwEaj9DnTCVA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1 - 0s - loss: 0.5496 - accuracy: 0.8750\n",
      "Restored model, accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGXqd4wWJl8O"
   },
   "source": [
    "Kỹ thuật này giúp chúng ta lưu mọi thứ:\n",
    "\n",
    "* Trọng số\n",
    "* Cấu trúc của mô hình\n",
    "* Cấu hình optimizer\n",
    "\n",
    "Keras lưu model bằng cách kiểm tra kiến trúc. Hiện tại, nó không thể lưu Tensorflow optimizers(from `tf.train`). Muốn sử dụng chúng thì cần phải re-compile lại model sau khi loading, và khi đó sẽ bị mất trạng thái hiện tại của optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPyhgcoVzqUB"
   },
   "source": [
    "### SavedModel format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LtcN4VIb7JkK"
   },
   "source": [
    "The SavedModel format là một cách khác để tuần tự hóa các models. Các mô hình được lưu ở định dạng này có thể được khôi phục bằng `tf.keras.models.load_model`. Phần bên dưới minh họa các bước để save và restoring mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sI1YvCDFzpl3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "1000/1000 [==============================] - 1s 608us/sample - loss: 1.1571 - accuracy: 0.6770\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 177us/sample - loss: 0.4204 - accuracy: 0.8780\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 185us/sample - loss: 0.2840 - accuracy: 0.9240\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 177us/sample - loss: 0.2068 - accuracy: 0.9490\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 177us/sample - loss: 0.1469 - accuracy: 0.9680\n",
      "WARNING:tensorflow:From /home/quanhm/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUvT_3qE8hV5"
   },
   "source": [
    "The SavedModel format is a directory containing a protobuf binary and a Tensorflow checkpoint. Inspect the saved model directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sq8fPglI1RWA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model\n",
      "assets\tsaved_model.pb\tvariables\n"
     ]
    }
   ],
   "source": [
    "# my_model directory\n",
    "!ls saved_model\n",
    "\n",
    "# Contains an assets folder, saved_model.pb, and variables folder.\n",
    "!ls saved_model/my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7qfpvpY9HCe"
   },
   "source": [
    "Reload a fresh Keras model from the saved model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YofwHdN0pxa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWwgNaz19TH2"
   },
   "source": [
    "The restored model is compiled with the same arguments as the original model. Try running evaluate and predict with the loaded model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yh5Mu0yOgE5J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1 - 0s - loss: 0.4462 - accuracy: 0.8530\n",
      "Restored model, accuracy: 85.30%\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kAUKJQyGqTNH"
   },
   "source": [
    "### Saving custom objects\n",
    "\n",
    "Sự khác biệt chính giữa HDF5 và SavingModel là HDF5 sử dụng các **object configs** để lưu kiến trúc model, trong khi SavingModel lưu **execution graph**(biểu đồ thực thi). Do đó, SavingModels có thể lưu các **object configs** như các **subclassed models** và các **custom layers** mà không yêu cầu mã nguồn.\n",
    "\n",
    "Để lưu các cấu hình object trong HDF5, cần những bước sau:\n",
    "\n",
    "1. Định nghĩa một phương thức `get_config` trong đối tượng của bạn và tùy chọn một lớp đối xứng `from_config`.\n",
    "  * `get_config (self)` trả về một từ điển JSON-serializable các tham số cần thiết để tạo lại đối tượng.\n",
    "  * `from_config(cls, config)` sử dụng cấu hình được trả về từ `get_config` để tạo một đối tượng mới. Mặc định, chức năng này sẽ sử dụng cấu hình làm kwargs khởi tạo (return cls (** config)).\n",
    "2. Truyền đối tượng cho đối số custom_objects khi tải mô hình. Đối số phải là một từ điển ánh xạ tên lớp chuỗi sang lớp Python. E.g. `tf.keras.models.load_model(path, custom_objects={'CustomLayer': CustomLayer})`\n",
    "\n",
    "See the [Writing layers and models from scratch](https://www.tensorflow.org/guide/keras/custom_layers_and_models) tutorial for examples of custom objects and `get_config`.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "save_and_load.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
